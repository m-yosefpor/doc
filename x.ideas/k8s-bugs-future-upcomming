k8s known issues, which does not have any solution/workarounds yet:
- small files issue
- disk io qos in k8s layer (cgroup v2)
.... not being declarative
- cinder state stuck in reserved/detaching.. what if ceph-csi?
- volumeattachment not found (fast scale down/up).. maybe solved in newer versions
- volume attached but not mounted.. maybe solved in newer versions


https://k8s.af


............. (mitigated)
- nf_conntrack -> increased a lot + monitoring/alert (many issues :D)
- ndot:5 -> node local caching + negative caching (no 0 ttl) + block AAAA (many issues)
- hpa -> never use
- clusterautoscaler -> never user
- automatic upgrade -> pin up to patch version (dnsmasq issue, terraform template issue, ksm issue)
- pod resource requests and limits -> clusterresourceoverride operator, 1:3 limit/req ratio
- pod priority and descheduler -> don't use.. also set quota and limit for ALL projects (even our infra) (fluentd preempted routers)
- create infra node roles which citical pods can fallback (or taint for critical, etc)
- scale-up consideration: be ware.. kubelet qos, multihashing, nfconntrack_hashsize_queue, haproxy reload scripts(many issues)
- pvc qos -> always use the ones which support qos
- previleged pods -> scc
- http flood - backend app of routes-> rate limiting (we have not enforced yet)
- any flood - internal svc -> we have project network isolation
.................. (somehow / maybe mitigated)
- cfs throttling -> throttling dashboard/alerts, increase the request/limit (many issues), GOMAXPROC
- emptydir -> alert.. should be limitabled
- pod BW consumption - enforce on pod with mutation (?)
- many files pvc- docker freez: Docker stucks in chowing lots of files (minio) ->  use crio: SELINUX: https://github.com/kubernetes/enhancements/issues/1710
................. (no solution yet)
- many files pvc- long startup (recursive chowning, chmoding and chconing! (minio,jira,confluence):
  SELINUX: https://github.com/kubernetes/enhancements/issues/1710
  enforce OnRootMismatch
- pod io wait, cause node highload avg (devops backup)
- many k8s operations (controller,scheduler,api): Don't run your cronjob every minute! (ode)
- dns flood (eck-operator) -> node local? OOM/throttled to send to central .. whatabout per pod?
- http flood - api-server
- http flood - router (smapp app)
- packet flood - ovs, node
............................ (always there)
- major changes -> release processes: staging, canary, approval, rollback/backup

............................. (??)
docker no-volume plugin
etcd-number-of-objects/size of each, space quota, etc
- users set taint?

security:
- userns -> anyuid
- cgroup ns
- cgroup v2
-




Namespaced CRDs:
- users can not write and use operators
- multiple operators (with different CRD/version) will collide even if they have limited to some namespaces lig OperatorGroup



many of operators does not emmit enough events, instead they only log (appset controller, ...) which is not possible for users to debug, only requires a cluster-admin then.






- api changes (renames)
- big nodes: kubelet , draining https://learnk8s.io/kubernetes-node-size

upcomming:
  security:
  - userns -> anyuid
  - cgroup ns
  - cgroup v2
  burstable cfs
  qos on network in podSpec (annotation?)
  qos on blkio in podSpec (cgroupv2)
  - ephermeral containers for debugging distroless containers

